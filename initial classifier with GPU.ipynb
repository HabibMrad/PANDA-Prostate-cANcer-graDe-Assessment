{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport skimage.io\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport numpy as np\nimport pandas as pd","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/train.csv')\nprint(train_df.shape)\ntrain_df.head()","execution_count":2,"outputs":[{"output_type":"stream","text":"(10616, 4)\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"                           image_id data_provider  isup_grade gleason_score\n0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005f7aaab2800f6170c399693a96917</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n      <td>karolinska</td>\n      <td>4</td>\n      <td>4+4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN = '../input/panda-16x128x128-tiles-data/train'\nMASKS = '../input/panda-16x128x128-tiles-data/masks'","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dominant_color(a):\n    colors, count = np.unique(a.reshape(-1,a.shape[-1]), axis=0, return_counts=True)\n    return colors[count.argmax()]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getLabel(row):\n    if(row[1].get(3) == \"0+0\"):\n        return True, \"0\"\n    if(row[1].get(3) == \"3+3\"):\n        return True, \"3\"\n    if(row[1].get(3) == \"4+4\"):\n        return True, \"4\"\n    if(row[1].get(3) == \"5+5\"):\n        return True, \"5\"\n    return False, \"-1\"\n        \n\n\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimages = []\nlabels = []\nfor row,z in zip(train_df.iterrows(),tqdm(range(len(train_df)))):\n    b, l = getLabel(row)\n    if(b):\n        score = l\n        name = row[1].get(0)\n        for i in range(6):\n            if(not os.path.isfile(MASKS+'/'+name+\"_\"+str(i)+\".png\")):\n                break\n                \n            dis = get_dominant_color(np.asarray(Image.open(MASKS+'/'+name+\"_\"+str(i)+\".png\")))\n\n            if((3 in dis)|(4 in dis)|(5 in dis)):\n                im = Image.open(TRAIN+'/'+name+\"_\"+str(i)+\".png\")\n                images.append(im)\n                labels.append(score)\n            else:\n                im = Image.open(TRAIN+'/'+name+\"_\"+str(i)+\".png\")\n                images.append(im)\n                labels.append(0)\n                \n        \n            \n        \n        \n\n","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=10616.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fec716d3f474a2d936d755afd89ebad"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"tuple index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-00a2a7dac92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dominant_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMASKS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-ca40048e02d6>\u001b[0m in \u001b[0;36mget_dominant_color\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dominant_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(images))\nprint(len(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms\n\npreprocess = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass data(Dataset):\n\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n\n    def __len__(self):\n        return len(images)\n    \n    def __getitem__(self, idx):\n        sample = {'img': preprocess(self.images[idx]), 'label': self.labels[idx]}\n\n        return sample\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nmodel = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl')\nmodel.fc = nn.Linear(512, 4)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler\n\ndataset = data(images,labels)\n\nbatch_size = 1\nvalidation_split = .2\nshuffle_dataset = True\nrandom_seed= 42\n\n# Creating data indices for training and validation splits:\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n                                           sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                                sampler=valid_sampler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_num_correct(preds, labels):\n    return preds.argmax(dim=1).eq(labels).sum().item()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training Loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport copy\nimport torch.nn.functional as F\nmodel.to(\"cuda\")\nhighest_acc = 0.00\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nfor epoch in tqdm(range(11)):\n    model.train()\n    total_loss = 0\n    total_correct = 0\n    for data,z in zip(train_loader,tqdm(range(len(train_loader)))): # Get Batch\n        batch = data.get(\"img\")\n        tensor = batch.squeeze(-1).to(\"cuda\")\n        label = data.get(\"label\")\n        if(label[0] == \"3\"):   \n            label = \"1\"\n        if(label[0] == \"4\"):   \n            label = \"2\"\n        if(label[0] == \"5\"):   \n            label = \"3\"\n        if(label[0] == \"0\"):   \n            label = \"0\"\n        label = torch.tensor(int(label)).unsqueeze(0).to(\"cuda\")\n        preds = model(tensor) # Pass Batch n   \n        loss = F.cross_entropy(preds, label) # Calculate Loss\n        optimizer.zero_grad()\n        loss.backward() # Calculate Gradients\n        optimizer.step() # Update Weights\n        total_loss += loss.item()\n        if(preds.argmax(dim=1).item() == label.item()):\n            total_correct += 1\n    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n    val_correct = 0\n    for data in validation_loader: # Get Batch\n        model.eval()\n        batch = data.get(\"img\")\n        tensor = batch.squeeze(-1).to(\"cuda\")\n        label = data.get(\"label\")\n        if(label[0] == \"3\"):   \n            label = \"1\"\n        if(label[0] == \"4\"):   \n            label = \"2\"\n        if(label[0] == \"5\"):   \n            label = \"3\"\n        if(label[0] == \"0\"):   \n            label = \"0\"\n        label = torch.tensor(int(label)).unsqueeze(0).to(\"cuda\")\n        preds = model(tensor) # Pass Batch n\n        if(preds.argmax(dim=1).item() == label.item()):\n            val_correct += 1\n    print(\"Validation Accuracy:\", val_correct/len(validation_loader)*100,\"%\")  \n    print(\"\\n\")\n\n    if((val_correct/len(validation_loader)*100) > highest_acc):\n          highest_acc = (val_correct/len(validation_loader)*100)\n           best_model = copy.deepcopy(network)\n           print(\"This is the best model so far, saving...\")\n           torch.save(model,\"/kaggle/working/PandaModel.pth\")\nprint(\"Final Accuracy: \", highest_acc)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}